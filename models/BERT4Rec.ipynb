{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunj941031/ds-sa-cp2/blob/main/models/BERT4Rec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vg0sx3_eDd5",
        "outputId": "21f2bb18-a5d2-479e-b0d6-43ad810e7fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IatRo2Phd6_n",
        "outputId": "0527dfef-5150-4b67-9551-27da212628ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.9/dist-packages (7.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zaXMbpoEeB03"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls46hifUgmt8"
      },
      "source": [
        "# 1. 학습 parameter 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kQr30WC2eQ8E"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'data_path' : '/content/drive/MyDrive/fashion_campus_dataset',\n",
        "    \n",
        "    'sequence_len' : 50,\n",
        "    'mask_prob' : 0.3, # cloze task\n",
        "    'random_seed' : 123,\n",
        "\n",
        "    'num_layers' : 2, # block 수 (encoder layer 수)\n",
        "    'hidden_units' : 50, # Embedding size\n",
        "    'num_heads' : 2, # Multi-head layer 수 (병렬처리), hidden_units를 나눴을 때 나누어 떨어지게게\n",
        "    'dropout' : 0.15, # dropout의 비율\n",
        "\n",
        "    'epoch' : 5,\n",
        "    'patience' : 5,\n",
        "    'batch_size' : 256,\n",
        "    'lr' : 0.001,\n",
        "\n",
        "    'num_epochs' : 10,\n",
        "    'num_workers' : 4,\n",
        "    'val_data' : 3,\n",
        "    'delete_data' : False,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsuqMA2_gqXH"
      },
      "source": [
        "# 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pwHqzLnkgf4I"
      },
      "outputs": [],
      "source": [
        "class MakeSequenceDataSet():\n",
        "    \"\"\"\n",
        "    SequenceData 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'user_item.csv'))\n",
        "        if config['delete_data']:\n",
        "            self.df = self.delete_ones()\n",
        "\n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('itemId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_items, self.num_users = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['itemId'].apply(lambda x : self.item_encoder[x] + 1)\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df = self.df.sort_values(['user_idx', 'timestamp']) # 시간에 따른 정렬\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col:str) -> dict:\n",
        "        '''\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Return:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        '''\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "        \n",
        "        return encoder, decoder\n",
        "\n",
        "    def delete_ones(self) -> dict:\n",
        "        a = self.df.groupby('userId')['itemId'].size()\n",
        "        for i in a.index:\n",
        "            if a[i] <= config['val_data']:\n",
        "                del(a[i])\n",
        "        df_ = self.df.copy()\n",
        "        df_ = df_[df_['userId'].isin(a.index)]\n",
        "                \n",
        "        return df_\n",
        "\n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        '''\n",
        "        sequence data 생성\n",
        "\n",
        "        Return:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        '''\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        group_df = self.df.groupby('user_idx')\n",
        "        for user, item in group_df:\n",
        "            users[user].extend(item['item_idx'].tolist())\n",
        "\n",
        "        for user in users:\n",
        "            user_train[user] = users[user][:-config['val_data']]\n",
        "            user_valid[user] = users[user][-config['val_data']:] # 마지막 아이템 예측\n",
        "\n",
        "        return user_train, user_valid\n",
        "\n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iZf_2Zq9k4ix"
      },
      "outputs": [],
      "source": [
        "class BERTTrainDataSet(Dataset):\n",
        "    def __init__(self, user_train, num_users, num_items, sequence_len=200, mask_prob=0.15, random_seed=None):\n",
        "        self.user_train = user_train\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.sequence_len = sequence_len\n",
        "        self.mask_prob = mask_prob\n",
        "        self._all_items = set([i for i in range(1, self.num_items + 1)])\n",
        "\n",
        "        # rng\n",
        "        if random_seed is None:\n",
        "            self.rng = random.Random()\n",
        "        else:\n",
        "            self.rng = random.Random(random_seed)\n",
        "\n",
        "        # tokens\n",
        "        self.mask_token = self.num_items + 1\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        # 총 user 수(학습에 사용할 sequence 수수)\n",
        "        return self.num_users\n",
        "\n",
        "    def __getitem__(self, user):\n",
        "        seq = self.user_train[user]\n",
        "        tokens = []\n",
        "        labels = []\n",
        "        for s in seq[-self.sequence_len:]:\n",
        "            prob = np.random.random()\n",
        "            if prob < self.mask_prob:\n",
        "                prob /= self.mask_prob\n",
        "                # BERT 학습\n",
        "                # random 하게 80% 를 mask token 으로 변환\n",
        "                if prob < 0.8:\n",
        "                    # masking\n",
        "                    # mask_index : num_item + 1 , 0 : pad, 1 ~ num_item : item index\n",
        "                    tokens.append(self.mask_token)\n",
        "                elif prob < 0.9:\n",
        "                    # item random sampling (noise)\n",
        "                    tokens.append(np.random.randint(1, self.num_items))\n",
        "                else:\n",
        "                    # 나머지 10% 를 original token 으로 사용\n",
        "                    tokens.append(s)\n",
        "                labels.append(s) # 학습에 사용\n",
        "            # training 에 사용하지 않음 \n",
        "            else:\n",
        "                tokens.append(s)\n",
        "                labels.append(0) # 학습에 사용하지 않음, trivial\n",
        "\n",
        "        # zero padding \n",
        "        # tokens 와 labels 가 padding_len 보다 짧으면 zero padding 을 해준다. \n",
        "        padding_len = self.sequence_len - len(tokens)\n",
        "        \n",
        "        tokens = [0] * padding_len + tokens\n",
        "        labels = [0] * padding_len + labels\n",
        "        return torch.LongTensor(tokens), torch.LongTensor(labels)\n",
        "\n",
        "    def _getseq(self, user):\n",
        "        return self.user_train[user]\n",
        "\n",
        "    def random_neg_sampling(self, sold_items, num_item_sample):\n",
        "        nge_samples = random.sample(list(self._all_items - set(sold_items)), num_item_sample)\n",
        "        return nge_samples\n",
        "\n",
        "class BertEvalDataset(Dataset):\n",
        "    def __init__(self, u2seq, u2answer, sequence_len, mask_token, negative_samples):\n",
        "        self.u2seq = u2seq\n",
        "        self.users = sorted(self.u2seq.keys())\n",
        "        self.u2answer = u2answer\n",
        "        self.sequence_len = sequence_len\n",
        "        self.mask_token = mask_token\n",
        "        self.negative_samples = negative_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user = self.users[index]\n",
        "        seq = self.u2seq[user]\n",
        "        answer = self.u2answer[user]\n",
        "        negs = self.random_neg_sampling(sold_item=user, num_item_sample = 1)\n",
        "\n",
        "        candidates = answer + negs\n",
        "        labels = [1] * len(answer) + [0] * len(negs)\n",
        "\n",
        "        seq = seq + [self.mask_token]\n",
        "        seq = seq[-self.sequence_len:]\n",
        "        padding_len = self.sequence_len - len(seq)\n",
        "        seq = [0] * padding_len + seq\n",
        "\n",
        "        return torch.LongTensor(seq), torch.LongTensor(candidates), torch.LongTensor(labels)\n",
        "    \n",
        "    def random_neg_sampling(self, sold_items, num_item_sample : int):\n",
        "        nge_samples = random.sample(list(self._all_items - set(sold_items)), num_item_sample)\n",
        "        return nge_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN1cYr2MoqOk"
      },
      "source": [
        "# 3. 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Util"
      ],
      "metadata": {
        "id": "WmG9hPNv0ehl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    cudnn.deterministic = True\n",
        "    cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "MeQuNUuwQOJn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "id": "ihaTaFPBR4Dh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = nn.Parameter(torch.ones(features))\n",
        "        self.beta = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.beta"
      ],
      "metadata": {
        "id": "PV_0pdBnf5wx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    # layer가 많아지면 학습이 잘 안되는 현상\n",
        "    # 따라서, sub-layer들에 각각 dropout을 한 후 서로 residual connection을 적용하고, layer normalization 적용\n",
        "    def __init__(self, hidden_units, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.norm = LayerNorm(hidden_units)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sublayer, x):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        r = self.norm(x)\n",
        "        r = sublayer(r)\n",
        "\n",
        "        r = self.dropout(r)\n",
        "\n",
        "        return x + r"
      ],
      "metadata": {
        "id": "yViBKzGuiXQZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, hidden_units, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w_1 = nn.Linear(hidden_units, d_ff)\n",
        "        self.w_2 = nn.Linear(d_ff, hidden_units)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.activation(self.w_1(x))))"
      ],
      "metadata": {
        "id": "u7zJ2-uOSdnR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "3fXOiUlHq9ck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KaBmHAqnoPbb"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, hidden_units, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.hidden_units = hidden_units\n",
        "        self.dropout = nn.Dropout(dropout_rate) # dropout rate\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None, dropout=None):\n",
        "        \"\"\"\n",
        "            b = batch, ? = num_heads, L = sequence_len\n",
        "\n",
        "            Q: (b x ? x L x dim_Q)\n",
        "            K: (b x ? x L x dim_K)\n",
        "            V: (b x ? x L x dim_V)\n",
        "            ?: 1 (squeezed) or h (multi-head)\n",
        "            mask: (b x ? x L x L)\n",
        "            dropout: nn.Module\n",
        "            assuming dim_Q = dim_K\n",
        "        \"\"\"\n",
        "\n",
        "        # A: (b x ? x L x L)\n",
        "        attn_score = torch.matmul(Q, K.transpose(2, 3)) / math.sqrt(self.hidden_units)\n",
        "\n",
        "        # apply mask (the logit value of a padding token should be minus infinity)\n",
        "        if mask is not None:\n",
        "            attn_score = attn_score.masked_fill(mask == 0, -1e9) # 유사도가 0인 지점은 -infinity로 보내서 softmax 결과가 0이 아니게 함\n",
        "        \n",
        "        # getting normalized(probability) weights through softmax (when padding token, it'll be 0)\n",
        "        # P: (b x ? x L x L)\n",
        "        p_attn = F.softmax(attn_score, dim=-1)\n",
        "        \n",
        "        # apply dropout (with given dropout)\n",
        "        if dropout is not None:\n",
        "            p_attn = self.dropout(p_attn) # attention distribution 상대적 중요도\n",
        "\n",
        "        # (b x ? x L x L) @ (b x ? x L x dim_V) -> (b x ? x L x dim_V)\n",
        "        output = torch.matmul(p_attn, V)\n",
        "\n",
        "        return output, p_attn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, hidden_units, dropout=0.1):\n",
        "\n",
        "        \"\"\"\n",
        "            dim_V should be equal to hidden_units / num_heads\n",
        "            we assume dim_Q = dim_K = dim_V\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        assert hidden_units % num_heads == 0\n",
        "\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.dim_V = hidden_units // num_heads\n",
        "\n",
        "        # query, key, value, output 생성을 위한 Linear 모델 생성\n",
        "        self.W_Q = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
        "        self.W_K = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
        "        self.W_V = nn.Linear(hidden_units, hidden_units * num_heads, bias=False)\n",
        "\n",
        "        self.W_O = nn.Linear(hidden_units * num_heads, hidden_units, bias=False)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(hidden_units, dropout)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layerNorm = LayerNorm(hidden_units)\n",
        "\n",
        "    def forward(self, enc, mask):\n",
        "\n",
        "        residual = enc\n",
        "\n",
        "        batch_size, seqlen = enc.size(0), enc.size(1)\n",
        "\n",
        "        # 1) Do all the linear projections in a batch from dim_model, then split into (num_heads x dim_V)\n",
        "        # [process]\n",
        "        # (1) linear(W): (b x L x dim_model) -> (b x L x dim_model)\n",
        "        # (2) view: (b x L x dim_model) -> (b x L x num_heads x dim_V)\n",
        "        # (3) transpose: (b x L x num_heads x dim_V) -> (b x num_heads x L x dim_V)\n",
        "        # Query, Key, Value를 (num_head)개의 Head로 나누어 각기 다른 Linear projection을 통과시킴\n",
        "        Q = self.W_Q(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units).transpose(1, 2)\n",
        "        K = self.W_K(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units).transpose(1, 2)\n",
        "        V = self.W_V(enc).view(batch_size, seqlen, self.num_heads, self.hidden_units).transpose(1, 2)\n",
        "\n",
        "        # 2) Apply attention to the projected vectors in the batch\n",
        "        # note that attenion only cares about the last two dimensions\n",
        "        # output: (b x num_heads x L x dim_V)\n",
        "        # Head별로 각기 다른 attention이 가능하도록 각각 attention에 통과시킴\n",
        "        output, attn_dist = self.attention(Q, K, V, mask=mask, dropout=self.dropout) # attn_dist : (batch_size, num_heads, sequence_len, sequence_len)\n",
        "\n",
        "        # 3) \"concat\" those heads using view\n",
        "        # [process]\n",
        "        # (1) transpose: (b x num_heads x L x dim_V) -> (b x L x num_heads x dim_V)\n",
        "        # (2) contiguous: reorder memory inside GPU (no dimension change)\n",
        "        # (3) view: (b x L x num_heads x dim_V) -> (b x L x dim_model)\n",
        "        # 다시 Transpose한 후 모든 head들의 attention 결과를 합칩니다.\n",
        "        output = output.transpose(1, 2).contiguous() # (batch_size, sequence_len, num_heads, d_model) / contiguous() : 가변적 메모리 할당\n",
        "        output = output.view(batch_size, seqlen, -1) # (batch_size, sequence_len, d_model * num_heads)\n",
        "\n",
        "        # 4) apply the final linear\n",
        "        # X: (b x L x dim_model)\n",
        "        output = self.layerNorm(self.dropout(self.W_O(output)) + residual)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "-Xr1eb1UubmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Bidirectional Encoder = Transformer (self-attention)\n",
        "    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_units=256, num_heads=4, d_ff=1024, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param hidden_units: hidden_units size of transformer\n",
        "        :param num_heads: head sizes of multi-head attention\n",
        "        :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_units\n",
        "        :param dropout: dropout rate\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(num_heads=num_heads, hidden_units=hidden_units, dropout=dropout)\n",
        "        self.attention_sublayer = SublayerConnection(hidden_units=hidden_units, dropout=dropout)\n",
        "        self.pwff = PositionwiseFeedForward(hidden_units=hidden_units, d_ff=d_ff, dropout=dropout)\n",
        "        self.pwff_sublayer = SublayerConnection(hidden_units=hidden_units, dropout=dropout)\n",
        "        self.dropoutlayer = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_enc, mask=None):\n",
        "        # we need dynamic mask for the attention forward (sublayer module also has parameters, namely layernorm)\n",
        "        # x: (b x L x dim_model)\n",
        "        # mask: (b x L x L), set False to ignore that point\n",
        "        x = self.attention_sublayer(lambda _x: self.attention(_x, mask=mask), input_enc)\n",
        "        x = self.pwff_sublayer(self.pwff, x)\n",
        "        return self.dropoutlayer(x)\n",
        "\n",
        "class BERT4Rec(nn.Module):\n",
        "    def __init__(self, num_users, num_items, sequence_len, device, num_layers=2, hidden_units=256, num_heads=4, dropout=0.1, random_seed=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # params\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.sequence_len = sequence_len\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_units = hidden_units\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.random_seed = random_seed\n",
        "        self.device = device\n",
        "        \n",
        "        # set seed\n",
        "        if random_seed is not None:\n",
        "            fix_random_seed(random_seed)\n",
        "\n",
        "        # 0: padding token\n",
        "        # 1 ~ V: item tokens\n",
        "        # V + 1: mask token\n",
        "\n",
        "        # Embedding layers\n",
        "        self.item_emb = nn.Embedding(num_items + 2, hidden_units, padding_idx=0) # padding : 0 / item : 1 ~ num_item + 1 /  mask : num_item + 2\n",
        "        self.pos_emb = nn.Embedding(sequence_len, hidden_units) # learnable positional encoding\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.emb_layernorm = nn.LayerNorm(hidden_units, eps=1e-6)\n",
        "\n",
        "        # transformer layers\n",
        "        self.transformers = nn.ModuleList([\n",
        "            TransformerBlock(\n",
        "                hidden_units=hidden_units,\n",
        "                num_heads=num_heads,\n",
        "                d_ff=hidden_units*4,\n",
        "                dropout=dropout\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.out = nn.Linear(hidden_units, num_items + 1)\n",
        "    \n",
        "    def forward(self, tokens):\n",
        "        L = tokens.shape[1]\n",
        "\n",
        "        # mask for whether padding token or not in attention matrix (True if padding token)\n",
        "        # [process] (b x L) -> (b x 1 x L) -> (b x L x L) -> (b x 1 x L x L)\n",
        "        token_mask = torch.BoolTensor(tokens > 0).unsqueeze(1).repeat(1, L, 1).unsqueeze(1).to(self.device)\n",
        "\n",
        "        # get embedding\n",
        "        # [process] (b x L) -> (b x L x d)\n",
        "        seqs = self.item_emb(torch.LongTensor(tokens).to(self.device))  # (batch_size, sequence_len, hidden_units)\n",
        "        positions = np.tile(np.array(range(tokens.shape[1])), [tokens.shape[0], 1])  # (batch_size, sequence_len)\n",
        "        seqs += self.pos_emb(torch.LongTensor(positions).to(self.device))  # (batch_size, sequence_len, hidden_units)\n",
        "        seqs = self.emb_layernorm(self.dropout(seqs))  # LayerNorm\n",
        "\n",
        "        # apply multi-layered transformers\n",
        "        # [process] (b x L x d) -> ... -> (b x L x d)\n",
        "        for transformer in self.transformers:\n",
        "            seqs = transformer(seqs, token_mask)\n",
        "\n",
        "        # classifier\n",
        "        # [process] (b x L x d) -> (b x L x (V + 1))\n",
        "        out = self.out(seqs)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "xtf_I6wZqtsL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER_MsqHwET7d"
      },
      "source": [
        "# 4. 학습함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Solver:\n",
        "    def calculate_loss(self, batch):\n",
        "        \n",
        "        self.ce_losser = CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "        # device\n",
        "        tokens = batch['tokens'].to(self.device)  # b x L\n",
        "        labels = batch['labels'].to(self.device)  # b x L\n",
        "\n",
        "        # forward\n",
        "        logits = self.model(tokens)  # b x L x (V + 1)\n",
        "\n",
        "        # loss\n",
        "        logits = logits.view(-1, logits.size(-1))  # bL x (V + 1)\n",
        "        labels = labels.view(-1)  # bL\n",
        "        loss = self.ce_losser(logits, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def set_model_mode(self, purpose: str) -> None:\n",
        "        if purpose == 'eval':\n",
        "            self.model = self.model.eval()  # type: ignore\n",
        "        elif purpose == 'train':\n",
        "            self.model = self.model.train()\n",
        "\n",
        "    def solve(self) -> None:\n",
        "        C = self.config\n",
        "        name = C['name']\n",
        "        print(f\"solve {name} start\")\n",
        "\n",
        "        # report new session\n",
        "        self.logger.info(\"-- new solve session started --\")\n",
        "\n",
        "        # report model parameters\n",
        "        numels = []\n",
        "        for parameter in self.model.parameters():\n",
        "            if parameter.requires_grad:\n",
        "                numels.append(parameter.numel())\n",
        "        num_params = sum(numels)\n",
        "        self.logger.info(f\"total parameters:\\t{num_params}\")\n",
        "        with open(os.path.join(self.data_dir, 'meta.json'), 'w') as fp:\n",
        "            json.dump({'num_params': num_params}, fp)\n",
        "\n",
        "        # solve loop\n",
        "        self.early_stop = False\n",
        "        self.patience_counter = 0\n",
        "        self.load_model('train')\n",
        "        for epoch in range(self.start_epoch, C['train']['epoch'] + 1):\n",
        "            self.solve_train(epoch)\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step()\n",
        "            if self.early_stop:\n",
        "                break\n",
        "\n",
        "        # solve end\n",
        "        self.load_model('test')\n",
        "        self.solve_test()\n",
        "\n",
        "    def solve_train(self, epoch: int) -> None:\n",
        "            self.train_one_epoch(epoch)\n",
        "            self.evaluate_on_valid(epoch)\n",
        "\n",
        "    def train_one_epoch(self, epoch: int) -> None:\n",
        "        # prepare\n",
        "        self.set_model_mode('train')\n",
        "        epoch_loss_sum = 0.0\n",
        "        epoch_loss_count = 0\n",
        "\n",
        "        # loop\n",
        "        pbar = tqdm(self.train_dataloader)\n",
        "        pbar.set_description(f\"[epoch {epoch} train]\")\n",
        "        for batch in pbar:\n",
        "\n",
        "            # get loss\n",
        "            loss = self.calculate_loss(batch)\n",
        "\n",
        "            # backward\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # step end\n",
        "            epoch_loss_sum += float(loss.data)\n",
        "            epoch_loss_count += 1\n",
        "            pbar.set_postfix(loss=f'{epoch_loss_sum / epoch_loss_count:.4f}')\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        # epoch end\n",
        "        epoch_loss = epoch_loss_sum / epoch_loss_count\n",
        "        self.logger.info('\\t'.join([\n",
        "            f\"[epoch {epoch}]\",\n",
        "            f\"train loss: {epoch_loss:.4f}\"\n",
        "        ]))\n",
        "        self.writer.add_scalar('train_loss', epoch_loss, epoch)\n",
        "\n",
        "    def evaluate_on_valid(self, epoch: int) -> None:\n",
        "        self.logger.info(f\"<evaluate on valid (epoch: {epoch})>\")\n",
        "        C = self.config\n",
        "\n",
        "        # prepare\n",
        "        self.set_model_mode('eval')\n",
        "        ks = sorted(C['metric']['ks'])\n",
        "        pivot = C['metric']['pivot']\n",
        "\n",
        "        # init\n",
        "        result_values = []\n",
        "\n",
        "        # loop\n",
        "        pbar = tqdm(self.valid_dataloader)\n",
        "        pbar.set_description(f\"[epoch {epoch} valid]\")\n",
        "        with torch.no_grad():\n",
        "            for batch in pbar:\n",
        "\n",
        "                # get rankers\n",
        "                rankers = self.calculate_rankers(batch)\n",
        "\n",
        "                # evaluate\n",
        "                labels = batch['labels'].to(self.device)\n",
        "                batch_results = calc_batch_rec_metrics_per_k(rankers, labels, ks)  # type: ignore\n",
        "                result_values.extend(batch_results['values'][pivot])\n",
        "\n",
        "                # verbose\n",
        "                pbar.set_postfix(pivot_score=f'{sum(result_values) / len(result_values):.4f}')\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "        # report\n",
        "        pivot_score = sum(result_values) / len(result_values)\n",
        "        self.logger.info('\\t'.join([\n",
        "            f\"[epoch {epoch}]\",\n",
        "            f\"valid pivot score: {pivot_score:.4f}\"\n",
        "        ]))\n",
        "        self.writer.add_scalar('valid_pivot_score', pivot_score, epoch)\n",
        "\n",
        "        # save best\n",
        "        if self.best_score is None or self.best_score < pivot_score:\n",
        "            self.best_score = pivot_score\n",
        "            torch.save(self.model.state_dict(), self.model_path)\n",
        "            self.logger.info(f\"updated best model at epoch {epoch} with pivot score {pivot_score}\")\n",
        "            self.patience_counter = 0\n",
        "        else:\n",
        "            self.patience_counter += 1\n",
        "        if self.patience_counter >= C['train']['patience']:\n",
        "            self.logger.info(f\"no update for {self.patience_counter} epochs, thus early stopping\")\n",
        "            self.early_stop = True\n",
        "\n",
        "        # save checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'best_score': self.best_score,\n",
        "            'model': self.model.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "        }, self.check_path)"
      ],
      "metadata": {
        "id": "X1hDGNZsBofe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "def train_one_epoch(epoch, train_dataloader):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss_sum = 0.0\n",
        "    epoch_loss_count = 0\n",
        "\n",
        "    pbar = tqdm(train_dataloader)\n",
        "    pbar.set_description(f\"[epoch {epoch} train\")\n",
        "    \n",
        "    for batch in pbar:\n",
        "        loss = calculate_loss(batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_sum += float(loss.data)\n",
        "        epoch_loss_count += 1\n",
        "        pbar.set_postfix(loss=f'{epoch_loss_sum / epoch_loss_count:.4f}')\n",
        "    \n",
        "    pbar.close()\n",
        "\n",
        "    epoch_loss = epoch_loss_sum / epoch_loss_count\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate_on_valid(epoch, valid_dataloader):\n",
        "    model.eval()\n",
        "    \n",
        "    NDCG = 0.0\n",
        "    HIT = 0.0\n",
        "\n",
        "    num_item_sample = 100\n",
        "    users = [user for user in range(make_sequence_dataset.num_user)]\n",
        "    \n",
        "    result_values = []\n",
        "\n",
        "    pbar = tqdm(valid_dataloader)\n",
        "    pbar.set_description(f\"[epoch {epoch} valid\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in pbar:\n",
        "            rankers = calculate_rankers(batch)\n",
        "\n",
        "            labels = batch['labels'].to(config['device'])\n",
        "            \n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer, data_loader):\n",
        "    \n",
        "    for epoch in range(1, config['num_epochs'] + 1):\n",
        "        train_loss = train_one_epoch(epoch,data_loader)\n",
        "\n",
        "\n",
        "\n",
        "    for seq, labels in data_loader:\n",
        "        logits = model(seq)\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "        labels = labels.view(-1).to(config['device'])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss_val += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss_val /= len(data_loader)\n",
        "\n",
        "    return loss_val\n",
        "\n",
        "def evaluate(model, user_train, user_valid, max_len, bert4rec_dataset, make_sequence_dataset):\n",
        "    model.eval()\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    num_item_sample = 100\n",
        "\n",
        "    users = [user for user in range(make_sequence_dataset.num_user)]\n",
        "\n",
        "    for user in users:\n",
        "        seq = (user_train[user] + [make_sequence_dataset.num_item + 1])[-max_len:]\n",
        "        rated = user_train[user] + user_valid[user]\n",
        "        items = user_valid[user] + bert4rec_dataset.random_neg_sampling(rated_item = rated, num_item_sample = num_item_sample)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            predictions = -model(np.array([seq]))\n",
        "            predictions = predictions[0][-1][items] # sampling\n",
        "            rank = predictions.argsort().argsort()[0].item()\n",
        "\n",
        "        if rank < 10: #Top10\n",
        "            NDCG += 1 / np.log2(rank + 2)\n",
        "            HIT += 1\n",
        "\n",
        "    NDCG /= len(users)\n",
        "    HIT /= len(users)\n",
        "\n",
        "    return NDCG, HIT\n",
        "\n",
        "def calculate_loss(batch):\n",
        "        \n",
        "    ce_losser = CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    # device\n",
        "    tokens = batch['tokens'].to(config['device'])  # b x L\n",
        "    labels = batch['labels'].to(config['device'])  # b x L\n",
        "\n",
        "    # forward\n",
        "    logits = model(tokens)  # b x L x (V + 1)\n",
        "\n",
        "    # loss\n",
        "    logits = logits.view(-1, logits.size(-1))  # bL x (V + 1)\n",
        "    labels = labels.view(-1)  # bL\n",
        "    loss = ce_losser(logits, labels)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def calculate_rankers(batch):\n",
        "\n",
        "    # device\n",
        "    tokens = batch['tokens'].to(config['device'])  # b x L\n",
        "    cands = batch['cands'].to(config['device'])  # b x C\n",
        "\n",
        "    # forward\n",
        "    logits = model(tokens)  # b x L x (V + 1)\n",
        "\n",
        "    # gather\n",
        "    logits = logits[:, -1, :]  # b x (V + 1)\n",
        "    scores = logits.gather(1, cands)  # b x C\n",
        "    rankers = scores.argsort(dim=1, descending=True)\n",
        "\n",
        "    return rankers"
      ],
      "metadata": {
        "id": "Jf2zw6CXzM6o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(scores, labels, k):\n",
        "    scores = scores.cpu()\n",
        "    labels = labels.cpu()\n",
        "    rank = (-scores).argsort(dim=1)\n",
        "    cut = rank[:, :k]\n",
        "    hit = labels.gather(1, cut)\n",
        "    return (hit.sum(1).float() / labels.sum(1).float()).mean().item()\n",
        "\n",
        "\n",
        "def ndcg(scores, labels, k):\n",
        "    scores = scores.cpu()\n",
        "    labels = labels.cpu()\n",
        "    rank = (-scores).argsort(dim=1)\n",
        "    cut = rank[:, :k]\n",
        "    hits = labels.gather(1, cut)\n",
        "    position = torch.arange(2, 2+k)\n",
        "    weights = 1 / torch.log2(position.float())\n",
        "    dcg = (hits.float() * weights).sum(1)\n",
        "    idcg = torch.Tensor([weights[:min(n, k)].sum() for n in labels.sum(1)])\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg.mean()\n",
        "\n",
        "\n",
        "def recalls_and_ndcgs_for_ks(scores, labels, ks):\n",
        "    metrics = {}\n",
        "\n",
        "    scores = scores.cpu()\n",
        "    labels = labels.cpu()\n",
        "    answer_count = labels.sum(1)\n",
        "    answer_count_float = answer_count.float()\n",
        "    labels_float = labels.float()\n",
        "    rank = (-scores).argsort(dim=1)\n",
        "    cut = rank\n",
        "    for k in sorted(ks, reverse=True):\n",
        "       cut = cut[:, :k]\n",
        "       hits = labels_float.gather(1, cut)\n",
        "       metrics['Recall@%d' % k] = (hits.sum(1) / answer_count_float).mean().item()\n",
        "\n",
        "       position = torch.arange(2, 2+k)\n",
        "       weights = 1 / torch.log2(position.float())\n",
        "       dcg = (hits * weights).sum(1)\n",
        "       idcg = torch.Tensor([weights[:min(n, k)].sum() for n in answer_count])\n",
        "       ndcg = (dcg / idcg).mean()\n",
        "       metrics['NDCG@%d' % k] = ndcg\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "W6TvWguEj-PY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxqJK--xKgyb"
      },
      "source": [
        "# 5. 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "63fbu_6GKbbV"
      },
      "outputs": [],
      "source": [
        "make_sequence_dataset = MakeSequenceDataSet(config=config)\n",
        "user_train, user_valid = make_sequence_dataset.get_train_valid_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rpe4KS4qWybY"
      },
      "outputs": [],
      "source": [
        "bert4rec_dataset = BERTTrainDataSet(\n",
        "    user_train = user_train, \n",
        "    sequence_len = config.sequence_len, \n",
        "    num_users = make_sequence_dataset.num_users, \n",
        "    num_items = make_sequence_dataset.num_items,\n",
        "    mask_prob = config.mask_prob,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gIIjMMm7XR_v"
      },
      "outputs": [],
      "source": [
        "data_loader = DataLoader(\n",
        "    bert4rec_dataset, \n",
        "    batch_size = config.batch_size, \n",
        "    shuffle = True, \n",
        "    pin_memory = True,\n",
        "    num_workers = config.num_workers,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "37s2MFEqXZil"
      },
      "outputs": [],
      "source": [
        "model = BERT4Rec(\n",
        "    num_users = make_sequence_dataset.num_users, \n",
        "    num_items = make_sequence_dataset.num_items, \n",
        "    hidden_units = config.hidden_units, \n",
        "    num_heads = config.num_heads, \n",
        "    num_layers = config.num_layers, \n",
        "    sequence_len = config.sequence_len, \n",
        "    dropout = config.dropout, \n",
        "    device = device,\n",
        "    ).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0) # label이 0인 경우 무시\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for seq, lab in data_loader:\n",
        "    pred = model(seq)\n",
        "    print(seq, pred[i], lab, sep='\\n')\n",
        "    break"
      ],
      "metadata": {
        "id": "eQljaPfwfnYU",
        "outputId": "33c929e1-2e82-4f90-feb6-fac37746894a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ..., 41990,  3059,  9710],\n",
            "        [    0,     0,     0,  ...,     0, 44447, 44447],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,   713, 25775, 37647],\n",
            "        [    0,     0,     0,  ...,     0, 44447, 25549],\n",
            "        [  407, 28907,  7360,  ..., 44158, 44447, 21371]])\n",
            "tensor([[1.7833e-02, -1.1847e+00, 6.1315e-01,  ..., 6.4790e-01, 2.5500e+00, -4.7862e+00],\n",
            "        [-2.4588e+00, 3.3134e+00, -1.3357e+00,  ..., 2.3007e-01, 6.5375e+00, 1.0142e+00],\n",
            "        [5.8477e-01, -1.0027e+00, -2.3372e+00,  ..., -3.8499e+00, 5.1656e-01, -3.5606e-01],\n",
            "        ...,\n",
            "        [2.3031e+00, -3.9614e-01, 1.2599e-01,  ..., 5.2885e-02, -1.0696e+00, -3.2918e-01],\n",
            "        [-3.3714e+00, -1.1389e+00, -3.5873e+00,  ..., -1.3834e-01, -2.1024e+00, 7.6059e-01],\n",
            "        [1.0810e+00, 4.3811e+00, -8.7558e-01,  ..., 7.6916e-01, 6.7901e-01, 9.9035e-01]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ...,     0, 15352, 28416],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ..., 29982,     0,     0],\n",
            "        [    0,     0,     0,  ...,     0, 13850,     0],\n",
            "        [    0,     0,     0,  ...,     0,  2692,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg(scores, labels, k):\n",
        "    scores = scores.cpu()\n",
        "    labels = labels.cpu()\n",
        "    rank = (-scores).argsort(dim=1)\n",
        "    cut = rank[:, :k]\n",
        "    hits = labels.gather(1, cut)\n",
        "    position = torch.arange(2, 2+k)\n",
        "    weights = 1 / torch.log2(position.float())\n",
        "    dcg = (hits.float() * weights).sum(1)\n",
        "    idcg = torch.Tensor([weights[:min(n, k)].sum() for n in labels.sum(1)])\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg.mean()"
      ],
      "metadata": {
        "id": "EpfARiJV1pxy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab = torch.as_tensor(lab, device=device)\n",
        "lab.is_cuda"
      ],
      "metadata": {
        "id": "Tm11Wu3Q3HxP",
        "outputId": "a8f5d24a-90ff-4b74-c6bd-9d3d233df753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.is_cuda"
      ],
      "metadata": {
        "id": "A2gpXKDGIAoR",
        "outputId": "4083b015-8574-411e-eeba-f388d7f15f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = (-pred[0]).argsort(dim=1)"
      ],
      "metadata": {
        "id": "C1dLrbslID5X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "LmhC1_N-aTyu",
        "outputId": "ad66a7a1-f1e2-4e70-e927-8b7646f35842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[41440, 43871, 14224,  ..., 34857,  6353,  1881],\n",
              "        [ 9268, 10660, 33855,  ..., 30175, 30977,  4902],\n",
              "        [25848, 12511, 29493,  ..., 15131, 13854, 44163],\n",
              "        ...,\n",
              "        [43763, 41551,    20,  ..., 36306, 43381, 28902],\n",
              "        [33607, 13143, 41969,  ..., 43550, 43387, 13763],\n",
              "        [13818, 21201, 16662,  ..., 11649,  5653,  7233]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred[0][0])"
      ],
      "metadata": {
        "id": "qDPiPXL7Xz4D",
        "outputId": "04584dd1-b991-4c4d-9c11-d5c7acd651be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44447"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(a[0][0])"
      ],
      "metadata": {
        "id": "gIKdxI3wYcjp",
        "outputId": "c88504f6-4007-4539-cc59-19514ec32c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44447"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "VJmjJXfyY08O",
        "outputId": "9b7f4469-dc74-4c90-f7b3-2608f3e25198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 50, 44447])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(2, 12)"
      ],
      "metadata": {
        "id": "S_RcHgc9AuHL",
        "outputId": "22bc4161-5376-46d6-963e-78b802f56e67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = 1 / torch.log2(torch.arange(2, 12).float())\n",
        "w"
      ],
      "metadata": {
        "id": "6YyK-dxSBxdr",
        "outputId": "77d112bb-180b-40e5-ae86-843f84cb11a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 6.3093e-01, 5.0000e-01, 4.3068e-01, 3.8685e-01, 3.5621e-01, 3.3333e-01, 3.1546e-01, 3.0103e-01,\n",
              "        2.8906e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[w[:min(n, 10)] for n in lab.sum(1)]"
      ],
      "metadata": {
        "id": "yGWUZXFUDqCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lab[1]"
      ],
      "metadata": {
        "id": "nLojW5B4bbfs",
        "outputId": "c0c4c758-4530-4349-c0ea-37a909c260e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 7588,    0,\n",
              "           0,    0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq[1]"
      ],
      "metadata": {
        "id": "jaapedk0bgSu",
        "outputId": "d1f1eaef-ba30-4a6d-9c5c-acf4b4090a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,  7588, 41990,  3059,  9710])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[w[:min(n, 10)].sum() for n in lab.sum(1)]"
      ],
      "metadata": {
        "id": "75wkeZd9BdaE",
        "outputId": "bb6a3185-c224-4a26-a553-6ea5abe9ac56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(0.),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00),\n",
              " tensor(4.5436e+00)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(-pred[0]).argsort(dim=1)"
      ],
      "metadata": {
        "id": "0zTspfBNH4vu",
        "outputId": "e49e0fb0-a5d6-4f00-d1e9-ce0798265a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[24501, 43561, 33713,  ...,  9640,  7493,  8154],\n",
              "        [17931, 40725, 26148,  ..., 25221, 38692, 30549],\n",
              "        [38063, 30048,  8127,  ..., 22023, 22998, 16706],\n",
              "        ...,\n",
              "        [15783,  7911, 15285,  ..., 44396, 40185,  6423],\n",
              "        [33203,  5985, 37703,  ...,  7334, 29168, 28501],\n",
              "        [38546, 23416, 40302,  ..., 34705, 21652, 11394]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cut = (-pred).argsort(dim=1)[:, :10]\n",
        "cut[0]"
      ],
      "metadata": {
        "id": "aUE2o9IUIYJ5",
        "outputId": "2e0f4086-ba9f-469a-9e75-a9884745c1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25,  4, 14,  ...,  1, 36, 29],\n",
              "        [ 1, 32, 20,  ..., 16, 12, 22],\n",
              "        [31, 47, 31,  ..., 49, 26, 44],\n",
              "        ...,\n",
              "        [49,  6, 23,  ..., 41, 31, 14],\n",
              "        [ 7, 19, 49,  ..., 12, 38,  5],\n",
              "        [46,  9, 19,  ..., 23, 33, 41]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.gather(1, cut)"
      ],
      "metadata": {
        "id": "9tnQJqOrIZkO",
        "outputId": "95748abb-dbc6-48ea-ce53-6bf7f0f1ed34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-74dd8b377437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YT68s7SS2uBF",
        "outputId": "07be2f21-3586-40ec-e9fa-3865ae12e9d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([124887392, 0, 121661072, 103567984, 139807589665344, 0, 0, 0, 0, 0],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cut[0]"
      ],
      "metadata": {
        "id": "8AqJY-RfABsi",
        "outputId": "d0eb4edf-4116-4897-e899-4561f439a21f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([         0,          0,          0,          0,          0,          1,\n",
              "                 0,          0,          0,          0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[0]"
      ],
      "metadata": {
        "id": "op-OBVPA6sDi",
        "outputId": "307da9c1-36df-4b9a-9e8b-cb11ed987b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.6826e+00, -4.2028e-01, -1.4675e+00,  ..., 5.8835e-01, -2.6691e+00, 3.7967e-01],\n",
              "        [-1.8520e+00, -5.9354e-01, 1.7134e+00,  ..., -1.3382e+00, 2.5389e+00, 9.2821e-01],\n",
              "        [3.5316e+00, 1.5960e+00, -2.5019e+00,  ..., 4.9782e-01, -3.0970e+00, 4.7133e-01],\n",
              "        ...,\n",
              "        [8.4954e-01, 4.0838e-01, 2.3736e+00,  ..., 9.7804e-02, -3.8567e-01, -4.5163e-01],\n",
              "        [2.0766e+00, -8.4078e-01, -1.8647e-02,  ..., 1.7163e+00, 4.0223e+00, -8.9374e-01],\n",
              "        [5.9893e+00, 1.0482e+00, 2.1059e+00,  ..., -2.1189e-02, -3.5698e+00, 1.6093e+00]],\n",
              "       device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXd4XtOb7Ksr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "id": "qIn0xhTOoISY",
        "outputId": "e9113173-cbdc-4b8b-ba80-ae3fd9823064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 50, 44447])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[:, -1, :].shape"
      ],
      "metadata": {
        "id": "5s1Rk5-0oBGA",
        "outputId": "f98dd99d-8cce-409a-d528-d76db6b7b356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 44447])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq.shape"
      ],
      "metadata": {
        "id": "fJ5tsoXC7PyU",
        "outputId": "4fac43b9-928c-430c-f9fc-7ab3e0a7c34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq[1]"
      ],
      "metadata": {
        "id": "mhnesG5L7quT",
        "outputId": "d8bc9974-dfb4-4267-8e6d-b9704b2eb3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0, 14421, 44447, 30265, 44447, 16811,\n",
              "         9227, 44447, 44447, 44447, 44447, 44447, 13249,  6750,   552, 44447,\n",
              "        25394, 30869, 14105, 27263, 32444, 44447,  8826, 44447, 15881, 16941])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab[1]"
      ],
      "metadata": {
        "id": "T0b3TDfx7u3W",
        "outputId": "a031085a-0b82-4f1f-d173-1e205f205335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0, 18549,     0,  7421,     0,\n",
              "            0, 20373, 31999, 40806, 16178, 36064,     0,  6750,     0, 24927,\n",
              "            0,     0,     0,     0,     0, 43540,     0, 31887,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(np.array(seq))[1][-1][item]"
      ],
      "metadata": {
        "id": "p4uq5eu5vGGI",
        "outputId": "f88fb5e4-509d-4685-90f9-4dfca32ffb60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.5180e+00, -4.6483e+00, 2.3331e+00, -2.2213e+00, 1.4559e+00, -3.4876e+00, 2.6763e+00, -1.3567e+00,\n",
              "        -8.0492e-01, 6.8982e-01, -7.5294e-01, 7.1165e-01, 1.8907e+00, -3.0660e-01, 1.7734e+00, 1.2953e+00,\n",
              "        -3.0323e+00, 2.4043e+00, -1.8935e+00, -1.6689e+00, -1.7942e-01, 2.2040e+00, -4.8107e+00, -8.8158e-03,\n",
              "        1.1862e+00, -2.2089e+00, -6.7169e-01, -2.1119e+00, -2.5307e+00, -1.7450e+00, -2.0174e+00, -2.8621e-01,\n",
              "        -3.1166e+00, 1.5495e+00, -1.7286e-01, 1.0464e+00, -1.4209e+00, -1.8008e+00, -1.8513e+00, -1.4855e+00,\n",
              "        -2.3269e-01, -6.6396e-01, -2.5133e+00, 1.4452e+00, 1.9394e+00, 1.6085e+00, 7.5975e-01, -1.9973e+00,\n",
              "        1.0125e+00, -2.8110e+00, 2.9417e+00, -2.9644e-01, -3.8430e+00, -1.0267e+00, 1.2913e+00, 4.2419e-01,\n",
              "        2.0089e+00, -1.8846e+00, 3.3864e+00, 1.4426e+00, -6.0401e-01, 3.4674e+00, -1.7923e+00, 1.9770e+00,\n",
              "        -1.4765e+00, 9.8734e-01, 1.7606e+00, -4.6233e+00, 4.8576e+00, 5.2621e+00, -1.9956e-01, 3.7990e-02,\n",
              "        -1.6113e+00, 1.4580e-01, 2.0387e+00, 9.6431e-01, 2.7893e+00, -1.8985e+00, -1.7322e+00, 3.4365e+00,\n",
              "        -1.3084e+00, 1.8353e+00, -2.6106e+00, 1.1307e+00, 2.3719e-01, -1.9586e+00, 4.2460e+00, -1.3886e+00,\n",
              "        -2.1969e-02, 4.8053e+00, 5.6769e-01, 2.2019e+00, -1.1041e+00, 2.1265e+00, -1.3169e+00, 4.0445e+00,\n",
              "        -1.6067e-01, -1.9259e+00, -3.3434e+00, 3.0298e+00, 4.6935e-01, 3.6531e+00, -3.0694e-01],\n",
              "       device='cuda:0', grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1]"
      ],
      "metadata": {
        "id": "KJDke72I_BUH",
        "outputId": "091259d4-cc70-4334-cd3d-3817b794b9a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.3098e-01, 5.8145e-01, -5.6312e-02,  ..., 3.2089e+00, 2.1743e+00, -8.6624e-01],\n",
              "       device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1].max(dim=0).indices.item()"
      ],
      "metadata": {
        "id": "abryb8aVlB5n",
        "outputId": "2fb8b248-0e8f-4f79-8d59-77eb7bf50b82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38558"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1]"
      ],
      "metadata": {
        "id": "3r4oU7TTuzRq",
        "outputId": "2cc1c2fb-2249-413a-ae5e-55acb4974cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.3098e-01, 5.8145e-01, -5.6312e-02,  ..., 3.2089e+00, 2.1743e+00, -8.6624e-01],\n",
              "       device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1].argsort(descending=True)[:10]"
      ],
      "metadata": {
        "id": "0l2vI0lbtHDB",
        "outputId": "5265d5eb-a6d2-4556-a350-106235fdb21e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([38558, 36962,  9616, 11158, 20558,  5987, 24070, 34526, 40637, 32153],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1].argsort(descending=True).argsort()[0].item()"
      ],
      "metadata": {
        "id": "GGH8enIktf4p",
        "outputId": "bee71bb9-f5da-4e49-9a12-c6b7e1287f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17405"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred[1][-1].argsort(descending=True).argsort()"
      ],
      "metadata": {
        "id": "f0-2aJxbtlvN",
        "outputId": "4c3a4bf4-5e56-4d53-cde0-18bba514920d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([17405, 16921, 22817,  ...,  1851,  5542, 30106], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(pred[1][-1]).item()"
      ],
      "metadata": {
        "id": "_6zPEjKA_Oo8",
        "outputId": "20d94d46-c464-4ca3-ac2c-a7bd5cbfc4d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.816342830657959"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.shape"
      ],
      "metadata": {
        "id": "VT7Ab-M97zE7",
        "outputId": "e29773ae-982c-44c0-f9b4-1db6d739ad33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(seq)"
      ],
      "metadata": {
        "id": "pWvCAaHjiIkw",
        "outputId": "da9cee2d-3fd8-4392-8f0b-37a59aa83e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred)"
      ],
      "metadata": {
        "id": "J-4D7mtj9tAW",
        "outputId": "f2dde6ef-2e9c-4fe4-beb8-7b51de22134f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred)"
      ],
      "metadata": {
        "id": "neODHU3490mg",
        "outputId": "75443d0d-fefe-4fdb-a670-d6e294dd28df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(seq[0])"
      ],
      "metadata": {
        "id": "nw35YBoE90kp",
        "outputId": "3abad1b6-479c-4b14-96a9-79efdabe5e8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lab[0])"
      ],
      "metadata": {
        "id": "hPj8MhED90ip",
        "outputId": "d440a028-0543-4dc4-b067-208c0f6a724b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_sequence_dataset.num_items"
      ],
      "metadata": {
        "id": "u-2XTywu90Mm",
        "outputId": "bc0424b4-278a-4d18-bcea-30d783c8d023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44446"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(data_loader)"
      ],
      "metadata": {
        "id": "tXHNNn6OptUu",
        "outputId": "ffa5bbae-6745-4cf2-bf47-c1d9bededc6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/199 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in pbar:\n",
        "    print(b)\n",
        "    print(len(b))\n",
        "    break"
      ],
      "metadata": {
        "id": "H_Y43a39ptSt",
        "outputId": "87831c90-a7c0-4906-dfe8-77b6f7b2f924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/199 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ..., 44011, 44447,  1911],\n",
            "        [    0,     0,     0,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [ 9612, 34684, 20060,  ..., 35536,  4024,   774],\n",
            "        [    0,     0,     0,  ..., 34182, 28249, 44447],\n",
            "        [    0,     0,     0,  ...,     0, 44447, 18931]]), tensor([[    0,     0,     0,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ...,     0, 16650,     0],\n",
            "        [    0,     0,     0,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    0, 34684, 20060,  ...,     0,     0,     0],\n",
            "        [    0,     0,     0,  ...,     0,     0,  9289],\n",
            "        [    0,     0,     0,  ...,     0, 43923,     0]])]\n",
            "2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_valid[3]"
      ],
      "metadata": {
        "id": "NT8hFSYRptQb",
        "outputId": "24ec0510-2bee-4805-ecb0-1d99b2b5a87e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[88]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFqrnARXptOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ucx3DjfptLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NR4LLsbIptJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rW1eU4UuptHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsXDRbehptBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pred.view(-1, pred.size(-1))))"
      ],
      "metadata": {
        "id": "iPguICJLgloX",
        "outputId": "0522c74b-a7a7-4b7f-ccae-39be5baf0570",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.view(-1, pred.size(-1))"
      ],
      "metadata": {
        "id": "oE8y31kJhRw9",
        "outputId": "78d9d85e-b4c7-42b0-a533-1a3de6ef040a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.0563e+00, -1.4749e+00, -1.0410e+00,  ..., -2.2281e-01,\n",
              "         -1.8372e+00, -6.6261e-03],\n",
              "        [-5.9312e+00, -1.0652e+00,  2.5878e+00,  ..., -4.2250e-01,\n",
              "          5.2795e+00, -3.9073e-01],\n",
              "        [-4.9632e-01,  1.4304e+00, -2.0105e-01,  ..., -2.6102e-01,\n",
              "         -5.1782e-01, -1.2004e+00],\n",
              "        ...,\n",
              "        [ 3.0043e-01,  1.5944e+00,  2.4671e-01,  ..., -7.9227e-01,\n",
              "          4.3174e-01,  3.0265e-03],\n",
              "        [ 1.0897e+00,  1.1239e+00, -1.6732e+00,  ...,  1.1516e+00,\n",
              "         -1.3626e+00, -8.4517e-01],\n",
              "        [ 2.2963e+00,  2.7915e+00,  1.7088e+00,  ..., -2.6057e+00,\n",
              "         -7.2375e-01,  1.9439e+00]], device='cuda:0', grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lab.view(-1)))"
      ],
      "metadata": {
        "id": "NFZymejshzjw",
        "outputId": "29d81639-855f-4f84-b0c1-6ee924ece3be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.view(-1)"
      ],
      "metadata": {
        "id": "sh03Sdngh7Vo",
        "outputId": "dbb6f1fd-f01b-4f1f-ff09-6536b7ee8f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sold = user_train[900] + user_valid[900]"
      ],
      "metadata": {
        "id": "YSFkjgSu19ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = user_valid[900] + bert4rec_dataset.random_neg_sampling(sold_items = sold, num_item_sample = 100)"
      ],
      "metadata": {
        "id": "L_OnwEfSrYBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred[0][-1])"
      ],
      "metadata": {
        "id": "5Rtqn15i5nX3",
        "outputId": "69296cf7-1076-4eb9-9fc8-6f30129c3749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44447"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pred[0][-1][item]"
      ],
      "metadata": {
        "id": "uvu8Pb1S2Tqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lab)"
      ],
      "metadata": {
        "id": "IxtnM7Uc8o-6",
        "outputId": "105ab058-8268-44a0-8e3f-a733493180e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.argsort().argsort()[0].item()"
      ],
      "metadata": {
        "id": "sBbncXFc5_rd",
        "outputId": "7f3477f1-5c37-4cf8-c97f-b49ce4827c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    ndcg_score(lab.cpu().numpy(), pred.cpu().numpy())"
      ],
      "metadata": {
        "id": "9_YC2cGH7MHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = ([0] * config['sequence_len'] + user_train[0] + [make_sequence_dataset.num_items + 1] * config['val_data'])[-config['sequence_len']:]"
      ],
      "metadata": {
        "id": "hCCYTcOeeops"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s"
      ],
      "metadata": {
        "id": "uweLTsAPi8gK",
        "outputId": "85c321bf-0bda-48f9-ee21-002dce5dff69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 44447,\n",
              " 44447,\n",
              " 44447]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(s)"
      ],
      "metadata": {
        "id": "YjF-prrjhOM9",
        "outputId": "b05d88cf-f8df-44fc-e724-e23183235d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = model(np.array([s]))"
      ],
      "metadata": {
        "id": "jdeeRBUvg7fD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p[0][-1][[0,1,2]]"
      ],
      "metadata": {
        "id": "B5XhHMELhWCH",
        "outputId": "491b6cb7-6556-4fa4-f548-5563b15d0694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.2289e+00, 4.0507e+00, 2.5109e+00], device='cuda:0',\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg(scores, labels, k):\n",
        "    scores = scores.cpu()\n",
        "    labels = labels.cpu()\n",
        "    rank = (-scores).argsort(dim=1)\n",
        "    cut = rank[:, :k]\n",
        "    hits = labels.gather(1, cut)\n",
        "    position = torch.arange(2, 2+k)\n",
        "    weights = 1 / torch.log2(position.float())\n",
        "    dcg = (hits.float() * weights).sum(1)\n",
        "    idcg = torch.Tensor([weights[:min(n, k)].sum() for n in labels.sum(1)])\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg.mean()"
      ],
      "metadata": {
        "id": "G2I20aQpf8oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, data_loader):\n",
        "    model.train()\n",
        "    loss_val = 0\n",
        "    for seq, labels in data_loader:\n",
        "        logits = model(seq)  # B x T x V\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))  # (B*T) x V\n",
        "        labels = labels.view(-1).to(device)  # B*T\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss_val += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss_val /= len(data_loader)\n",
        "\n",
        "    return loss_val\n",
        "\n",
        "def evaluate(model, user_train, user_valid, sequence_len, bert4rec_dataset, make_sequence_dataset):\n",
        "    model.eval()\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    num_item_sample = 100\n",
        "\n",
        "    users = [user for user in range(make_sequence_dataset.num_users)]\n",
        "\n",
        "    for user in users:\n",
        "        seq = ([0]*sequence_len + user_train[user] + [make_sequence_dataset.num_items + 1] * config['val_data'])[-sequence_len:]\n",
        "        sold = user_train[user] + user_valid[user]\n",
        "        items = user_valid[user] + bert4rec_dataset.random_neg_sampling(sold_items = sold, num_item_sample = num_item_sample)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            predictions = model(np.array([seq]))\n",
        "            predictions = predictions[0][-1][items] # sampling\n",
        "            rank = predictions.argsort().argsort()[0].item()\n",
        "\n",
        "        for i, r in enumerate(predictions):\n",
        "        if rank < 10: #Top10\n",
        "            NDCG += 1 / np.log2(rank + 2)\n",
        "            HIT += 1\n",
        "\n",
        "    NDCG /= len(users)\n",
        "    HIT /= len(users)\n",
        "\n",
        "    return NDCG, HIT"
      ],
      "metadata": {
        "id": "ETNnkwbl03H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjSWoKLmXa45"
      },
      "outputs": [],
      "source": [
        "loss_list = []\n",
        "ndcg_list = []\n",
        "hit_list = []\n",
        "for epoch in range(1, config['num_epochs'] + 1):\n",
        "    model.train()\n",
        "    tbar = tqdm(data_loader)\n",
        "    for _ in tbar:\n",
        "        train_loss = train(\n",
        "            model = model, \n",
        "            criterion = criterion, \n",
        "            optimizer = optimizer, \n",
        "            data_loader = data_loader)\n",
        "        \n",
        "        ndcg, hit = evaluate(\n",
        "            model = model, \n",
        "            user_train = user_train, \n",
        "            user_valid = user_valid, \n",
        "            sequence_len = config.sequence_len,\n",
        "            bert4rec_dataset = bert4rec_dataset, \n",
        "            make_sequence_dataset = make_sequence_dataset,\n",
        "            )\n",
        "\n",
        "        loss_list.append(train_loss)\n",
        "        ndcg_list.append(ndcg)\n",
        "        hit_list.append(hit)\n",
        "\n",
        "        tbar.set_description(f'Epoch: {epoch:3d}| Train loss: {train_loss:.5f}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IYFTapfXcvb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "ax = ax.flatten()\n",
        "epochs = [i for i in range(1, config.num_epochs + 1)]\n",
        "\n",
        "ax[0].plot(epochs, loss_list)\n",
        "ax[0].set_title('Loss')\n",
        "\n",
        "ax[1].plot(epochs, ndcg_list)\n",
        "ax[1].set_title('NDCG')\n",
        "\n",
        "ax[2].plot(epochs, hit_list)\n",
        "ax[2].set_title('HIT')\n",
        "plt.show()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRRUv2GcwM_I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJe+wJIGmKbF6yrmg3lxH8",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}