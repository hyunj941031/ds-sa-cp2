{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qBY9WErzzXxggssDR6JSg3GLv96dzOvS",
      "authorship_tag": "ABX9TyP5lbmFaFiJAwzUF29RqPDq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunj941031/ds-sa-cp2/blob/main/models/MF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX4plvyPUAe-",
        "outputId": "ce0611be-e409-4664-b0b5-2308910a3612"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.8/dist-packages (7.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1JWw0FeTnWR",
        "outputId": "56deac58-bd35-4248-c1b7-49fa6dd860cf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1CpW4ZeEfCYW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "from collections import defaultdict\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'data_path' : '/content/drive/MyDrive/fashion_campus_dataset',\n",
        "    'model_path' : './',\n",
        "    'model' : 'MF'\n",
        "}\n",
        "\n",
        "args = {\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 10,\n",
        "    \"num_factor\": 32,\n",
        "    \"lr\": 0.001,\n",
        "    \"num_layers\": 3,\n",
        "    \"num_ng\": 4,\n",
        "    \"out\": True,\n",
        "    \"test_num_ng\": 99,\n",
        "    \"top_k\": 10,\n",
        "}\n",
        "\n",
        "config = Box(config)\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = args[\"gpu\"]\n",
        "# cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "Tey380DAMK7R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitData():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'user_item.csv'), index_col=0)\n",
        "        self.df = self.delete_ones()\n",
        "\n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('itemId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['itemId'].apply(lambda x : self.item_encoder[x] + 1)\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df = self.df.sort_values(['user_idx', 'timestamp'])\n",
        "        self.user_train, self.user_valid = self.split_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col:str) -> dict:\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "\n",
        "    def delete_ones(self) -> dict:\n",
        "        a = self.df.groupby('userId')['itemId'].size()\n",
        "        for i in a.index:\n",
        "            if a[i] <= 1:\n",
        "                del(a[i])\n",
        "        df_ = self.df.copy()\n",
        "        df_ = df_[df_['userId'].isin(a.index)]\n",
        "        \n",
        "        return df_\n",
        "\n",
        "    def split_sequence_data(self) -> dict:\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        group_df = self.df.groupby('user_idx')\n",
        "        for user, item in group_df:\n",
        "            users[user].extend(item['item_idx'].tolist())\n",
        "\n",
        "        for user in users:\n",
        "            user_train[user] = users[user][:-1]\n",
        "            user_valid[user] = [users[user][-1]] # 마지막 아이템 예측\n",
        "\n",
        "        return user_train, user_valid\n",
        "\n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid\n",
        "\n",
        "split_data = SplitData(config)\n",
        "train_df, val_df = split_data.get_train_valid_data()"
      ],
      "metadata": {
        "id": "n85w6_OFDuxA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df), len(val_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj2PWFvFoZaM",
        "outputId": "c5879356-0d31-4020-fd45-032ed4e80a31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42231, 42231)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = split_data.df\n",
        "num_user = df['userId'].nunique()\n",
        "num_item = df['itemId'].nunique()\n",
        "\n",
        "sparsity = 1 - len(df) / (num_user * num_item)\n",
        "\n",
        "print(f'전체 User 수: {num_user}')\n",
        "print(f'전체 Item 수: {num_item}')\n",
        "print(f'행렬의 희소성: {sparsity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt08_KhxDtzR",
        "outputId": "8199cf54-d812-4e25-9851-9c2299070aba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 User 수: 42231\n",
            "전체 Item 수: 44446\n",
            "행렬의 희소성: 0.9993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = set()\n",
        "for i in range(len(train_df)):\n",
        "    for val in train_df[i]:\n",
        "        items.add(val)\n",
        "num_item = len(items) + 1\n",
        "num_user = len(train_df) + 1"
      ],
      "metadata": {
        "id": "GqFn1X0iIB6d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_item, num_user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3rGZy8WLP3q",
        "outputId": "cd9512e2-9025-461c-efed-2f799dc19f9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44447, 42232)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat = sp.dok_matrix((num_user, num_item), dtype=np.float32)\n",
        "train_data = []\n",
        "\n",
        "for i in range(len(train_df)):\n",
        "    for j in range(len(train_df[i])):\n",
        "        train_mat[i, train_df[i][j]] = 1.0\n",
        "        train_data.append([i,train_df[i][j]])"
      ],
      "metadata": {
        "id": "bhozSChII9cG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "\n",
        "for i in range(len(val_df)):\n",
        "    for j in range(len(val_df[i])):\n",
        "        test_data.append([i,val_df[i][j]])"
      ],
      "metadata": {
        "id": "ptIDP6-9kaow"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCFData(data.Dataset):\n",
        "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
        "        super(NCFData, self).__init__()\n",
        "        \"\"\" Note that the labels are only useful when training, we thus \n",
        "\t\t\tadd them in the ng_sample() function.\n",
        "\t\t\"\"\"\n",
        "        self.features_ps = features\n",
        "        self.num_item = num_item\n",
        "        self.train_mat = train_mat\n",
        "        self.num_ng = num_ng\n",
        "        self.is_training = is_training\n",
        "        self.labels = [0] * len(features)\n",
        "\n",
        "    def set_ng_sample(self):\n",
        "        assert self.is_training, \"no need to sampling when testing\"\n",
        "\n",
        "        # negative sample 더하기\n",
        "        self.features_ng = []\n",
        "        for x in self.features_ps:\n",
        "            # user\n",
        "            u = x[0]\n",
        "            for _ in range(self.num_ng):\n",
        "                j = np.random.randint(self.num_item)\n",
        "                # train set에 있는 경우 다시 뽑기\n",
        "                while (u, j) in self.train_mat:\n",
        "                    j = np.random.randint(self.num_item)\n",
        "                self.features_ng.append([u, j])\n",
        "\n",
        "        labels_ps = [1] * len(self.features_ps)\n",
        "        labels_ng = [0] * len(self.features_ng)\n",
        "\n",
        "        self.features_fill = self.features_ps + self.features_ng\n",
        "        self.labels_fill = labels_ps + labels_ng\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.num_ng + 1) * len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self.features_fill if self.is_training else self.features_ps\n",
        "        labels = self.labels_fill if self.is_training else self.labels\n",
        "\n",
        "        user = features[idx][0]\n",
        "        item = features[idx][1]\n",
        "        label = labels[idx]\n",
        "        return user, item, label"
      ],
      "metadata": {
        "id": "1QgtmdG41UdP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(train_data, test_data, num_item, train_mat):\n",
        "\n",
        "    # construct the train and test datasets\n",
        "    # args = (features, num_item, train_mat=None, num_ng=0, is_training=None)\n",
        "    train_dataset = NCFData(train_data, num_item, train_mat, args[\"num_ng\"], True)\n",
        "    test_dataset = NCFData(test_data, num_item, train_mat, 0, False)\n",
        "    train_loader = data.DataLoader(\n",
        "        train_dataset, batch_size=args[\"batch_size\"], shuffle=True, num_workers=4\n",
        "    )\n",
        "    test_loader = data.DataLoader(\n",
        "        test_dataset, batch_size=args[\"test_num_ng\"] + 1, shuffle=False, num_workers=0\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "train_loader, test_loader = prepare_data(train_data, test_data, num_item, train_mat)"
      ],
      "metadata": {
        "id": "A7fZa1cmF-vb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor):\n",
        "        super(MF, self).__init__()\n",
        "        self.num_factor = num_factor\n",
        "\n",
        "        self.embed_user = nn.Embedding(num_user, num_factor)\n",
        "        self.embed_item = nn.Embedding(num_item, num_factor)\n",
        "        predict_size = num_factor\n",
        "        self.predict_layer = torch.ones(predict_size, 1) # .cuda()\n",
        "        self._init_weight_()\n",
        "\n",
        "    def _init_weight_(self):\n",
        "        # weight 초기화\n",
        "        nn.init.normal_(self.embed_user.weight, std=0.01)\n",
        "        nn.init.normal_(self.embed_item.weight, std=0.01)\n",
        "\n",
        "        # bias 초기화\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        embed_user = self.embed_user(user)\n",
        "        embed_item = self.embed_item(item)\n",
        "        output_GMF = embed_user * embed_item\n",
        "        prediction = torch.matmul(output_GMF, self.predict_layer)\n",
        "        return prediction.view(-1)"
      ],
      "metadata": {
        "id": "qzMTr8rXEMHZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_user, num_item, args):\n",
        "    model = MF(num_user, num_item, args[\"num_factor\"])\n",
        "    # model.cuda()\n",
        "    loss_function = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
        "    return model, loss_function, optimizer\n",
        "\n",
        "model, loss_function, optimizer = create_model(num_user, num_item, args)"
      ],
      "metadata": {
        "id": "a9gOxuStDx3a"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hit(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def ndcg(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        index = pred_items.index(gt_item)\n",
        "        return np.reciprocal(np.log2(index + 2))\n",
        "    return 0\n",
        "\n",
        "\n",
        "def metrics(model, test_loader, top_k):\n",
        "    HR, NDCG = [], []\n",
        "\n",
        "    for user, item, _ in test_loader:\n",
        "        user = user # .cuda()\n",
        "        item = item # .cuda()\n",
        "\n",
        "        predictions = model(user, item)\n",
        "        # 가장 높은 top_k개 선택\n",
        "        _, indices = torch.topk(predictions, top_k)\n",
        "        # 해당 상품 index 선택\n",
        "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "        # 정답값 선택\n",
        "        gt_item = item[0].item()\n",
        "        HR.append(hit(gt_item, recommends))\n",
        "        NDCG.append(ndcg(gt_item, recommends))\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG)"
      ],
      "metadata": {
        "id": "hWNdVVIEL8T_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count, best_hr = 0, 0\n",
        "writer = SummaryWriter()  # for visualization\n",
        "# 모델 파라미터 출력\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    model.train()  # Enable dropout (if have).\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loader.dataset.set_ng_sample()\n",
        "\n",
        "    for user, item, label in train_loader:\n",
        "        user = user # .cuda()\n",
        "        item = item # .cuda()\n",
        "        label = label.float() # .cuda()\n",
        "\n",
        "        # gradient 초기화\n",
        "        model.zero_grad()\n",
        "        prediction = model(user, item)\n",
        "        loss = loss_function(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        writer.add_scalar(\"data/loss\", loss.item(), count)\n",
        "        count += 1\n",
        "\n",
        "    model.eval()\n",
        "    HR, NDCG = metrics(model, test_loader, args[\"top_k\"])\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"The time elapse of epoch {:03d}\".format(epoch)\n",
        "        + \" is: \"\n",
        "        + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time))\n",
        "    )\n",
        "    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
        "\n",
        "    if HR > best_hr:\n",
        "        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
        "        if args[\"out\"]:\n",
        "            if not os.path.exists(config[\"model_path\"]):\n",
        "                os.mkdir(config[\"model_path\"])\n",
        "            torch.save(\n",
        "                model, \"{}{}.pth\".format(config[\"model_path\"], config[\"model\"])\n",
        "            )\n",
        "\n",
        "print(\n",
        "    \"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
        "        best_epoch, best_hr, best_ndcg\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "wT7TfdzXTXDm",
        "outputId": "7fa42d92-16a8-441f-fcd2-aa06eef12a6e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time elapse of epoch 000 is: 00: 13: 38\n",
            "HR: 0.106\tNDCG: 0.042\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BoxKeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/box/box.cpython-38-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_path'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-518b7dc5bb97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbest_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_ndcg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDCG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             torch.save(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/box/box.cpython-38-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mBoxKeyError\u001b[0m: \"'model_path'\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMnnCmReIkl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}